{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse\n",
    "import json\n",
    "import string\n",
    "import pymorphy2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "from multiprocessing import Pool, cpu_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>image</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>itemId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>согласиться дорогой любитель собака до что же ...</td>\n",
       "      <td>[-0.169  0.129  0.067  0.019  0.281 -0.245  0....</td>\n",
       "      <td>пять забавный морщинистый порода собака</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>контур три поперечный улица состоять до недавн...</td>\n",
       "      <td>[-0.158 -0.112 -0.325  0.05  -0.114  0.002 -0....</td>\n",
       "      <td>история улица ирининский в гомель</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>источник http infodays ru вообще он как то сам...</td>\n",
       "      <td>[ 0.084 -0.181  0.008  0.34  -0.03  -0.197 -0....</td>\n",
       "      <td>зачем дудь весь время спрашивать гость програм...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41 летний светлана зейналов решить окрестить 5...</td>\n",
       "      <td>[ 0.034 -0.119 -0.062  0.025  0.128 -0.041  0....</td>\n",
       "      <td>светлана зейналов крестить младший дочь</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>организовать преступный группировка гбао делат...</td>\n",
       "      <td>[-0.061 -0.015 -0.198 -0.047  0.054  0.029 -0....</td>\n",
       "      <td>гкнб бандит в гбао делать вид что расстаться с...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  content  \\\n",
       "itemId                                                      \n",
       "0       согласиться дорогой любитель собака до что же ...   \n",
       "1       контур три поперечный улица состоять до недавн...   \n",
       "2       источник http infodays ru вообще он как то сам...   \n",
       "3       41 летний светлана зейналов решить окрестить 5...   \n",
       "4       организовать преступный группировка гбао делат...   \n",
       "\n",
       "                                                    image  \\\n",
       "itemId                                                      \n",
       "0       [-0.169  0.129  0.067  0.019  0.281 -0.245  0....   \n",
       "1       [-0.158 -0.112 -0.325  0.05  -0.114  0.002 -0....   \n",
       "2       [ 0.084 -0.181  0.008  0.34  -0.03  -0.197 -0....   \n",
       "3       [ 0.034 -0.119 -0.062  0.025  0.128 -0.041  0....   \n",
       "4       [-0.061 -0.015 -0.198 -0.047  0.054  0.029 -0....   \n",
       "\n",
       "                                                    title  \n",
       "itemId                                                     \n",
       "0                 пять забавный морщинистый порода собака  \n",
       "1                       история улица ирининский в гомель  \n",
       "2       зачем дудь весь время спрашивать гость програм...  \n",
       "3                 светлана зейналов крестить младший дочь  \n",
       "4       гкнб бандит в гбао делать вид что расстаться с...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items = pd.read_csv('../data/processed/processed_items.csv', index_col='itemId')\n",
    "items.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.models.keyedvectors as word2vec\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/external/ruwikiruscorpora_upos_skipgram_300_2_2019/model.bin'\n",
    "w2v_model = word2vec.KeyedVectors.load_word2vec_format(path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src/features')\n",
    "from w2v_stemmer import tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "914cd924dbdd4563ae7e02b2946c4137",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=248978), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded 248978 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = dict()\n",
    "for word in tqdm_notebook(w2v_model.vocab):\n",
    "    embeddings_index[word] = w2v_model[word]\n",
    "print('Loaded {} word vectors.'.format(len(embeddings_index)))\n",
    "\n",
    "gc.collect()\n",
    "all_embs = np.stack(list(embeddings_index.values()))\n",
    "emb_mean, emb_std = all_embs.mean(axis=0), all_embs.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/valeriy/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "#--------#\n",
    "\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "russian_stopwords = stopwords.words(\"russian\")\n",
    "\n",
    "def get_embedding(label: str) -> np.ndarray:\n",
    "    if isinstance(label, float):\n",
    "        return np.random.normal(emb_mean, emb_std, w2v_model.vector_size)\n",
    "    \n",
    "    words = [word for word in label.split() if word not in russian_stopwords]\n",
    "    \n",
    "    if not words:\n",
    "        return np.random.normal(emb_mean, emb_std, w2v_model.vector_size)\n",
    "    \n",
    "    label_embeddings = np.zeros((len(words), w2v_model.vector_size), dtype=np.float32)\n",
    "    \n",
    "    for i, word in enumerate(words):\n",
    "        if word not in w2v_model:\n",
    "            label_embeddings[i, :] = np.random.normal(emb_mean, emb_std, w2v_model.vector_size)\n",
    "            continue\n",
    "        tagged = tag(word)\n",
    "        if tagged:\n",
    "            label_embeddings[i, :] = w2v_model[tagged]\n",
    "            continue\n",
    "        label_embeddings[i, :] = np.random.normal(emb_mean, emb_std, w2v_model.vector_size)\n",
    "    \n",
    "    return label_embeddings.mean()\n",
    "            \n",
    "\n",
    "def get_embeddings(series: pd.Series):\n",
    "    output = np.zeros((len(series), w2v_model.vector_size), dtype=np.float32)\n",
    "    for i, label in tqdm_notebook(series.items(), total=len(series)):\n",
    "        output[i, :] = get_embedding(label)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a12383b2c954b76b92ceb15af14cf2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=328050), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(328050, 300)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_embeddings = get_embeddings(items['title'])\n",
    "title_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_features = scipy.sparse.hstack([\n",
    "    scipy.sparse.eye(len(items)), title_embeddings\n",
    "], format='csr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41931f801208462cb2918ce86cb94c06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=42977), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "row = []\n",
    "col = []\n",
    "\n",
    "train_lines = sum(1 for line in open('../data/interim/train.json','r'))\n",
    "\n",
    "with open('../data/interim/train.json') as train_file:\n",
    "    for i, line in enumerate(tqdm_notebook(train_file, total=train_lines)):\n",
    "        json_line = json.loads(line)\n",
    "        for item, rating in json_line['trainRatings'].items():\n",
    "            data.append((-1) ** (int(rating) + 1))\n",
    "            row.append(i)\n",
    "            col.append(int(item))\n",
    "train_int = scipy.sparse.coo_matrix((data, (row, col)))\n",
    "del data, row, col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x7f3c4c6e0780>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = lightfm.LightFM(no_components=32, loss=\"logistic\", random_state=42)\n",
    "model.fit(train_int, epochs=10, num_threads=cpu_count(), item_features=item_features, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.read_csv('../data/external/random_benchmark.csv')\n",
    "sample['pred'] = model.predict(\n",
    "    sample.userId.values,\n",
    "    sample.itemId.values,\n",
    "    item_features=item_features,\n",
    "    num_threads=cpu_count(),\n",
    ")\n",
    "sample.sort_values(['userId', 'pred'], ascending=[True, False], inplace=True)\n",
    "sample.drop(columns=['pred'], inplace=True)\n",
    "sample.to_csv('../predictions/lightfm_title_embeddings3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KAGGLE_USERNAME'] = \"klyukinv\"\n",
    "os.environ['KAGGLE_KEY'] = \"6fc43bd58892df21aa88d9f8ad6206ef\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 35.7M/35.7M [00:08<00:00, 4.38MB/s]\n",
      "Successfully submitted to Рекомендательная система для статей"
     ]
    }
   ],
   "source": [
    "!kaggle competitions submit -c 2018-hse-ml-competition-04 -f ../predictions/lightfm_title_embeddings3.csv -m \"Title embeddings (w2v) submission №3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
