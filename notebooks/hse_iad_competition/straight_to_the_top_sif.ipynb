{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse\n",
    "import json\n",
    "import string\n",
    "import pymorphy2\n",
    "import gc\n",
    "import gensim.models.keyedvectors as word2vec\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from fse.models import SIF\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "from multiprocessing import Pool, cpu_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../../data/external/ruwikiruscorpora_upos_skipgram_300_2_2019/model.bin'\n",
    "w2v_model = word2vec.KeyedVectors.load_word2vec_format(path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation = string.punctuation + '«»\\n--––'\n",
    "mapping = str.maketrans(punctuation, ' ' * len(punctuation))\n",
    "ma = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "def normalize_text(s):\n",
    "    return \" \".join(\n",
    "        [ma.normal_forms(word)[0] for word in s.translate(mapping).lower().split()]\n",
    "    )\n",
    "\n",
    "def normalize_line(line):\n",
    "    item = json.loads(line)\n",
    "    item['content'] = normalize_text(item['content'])\n",
    "    item['title'] = normalize_text(item['title'])\n",
    "    if isinstance(item['image'], float):\n",
    "        item['image'] = np.full((96,),0)\n",
    "    else:\n",
    "        item['image'] = np.array(item['image'])\n",
    "    return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = pd.read_csv('../../data/processed/processed_items.csv', index_col='itemId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>image</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>itemId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>согласиться дорогой любитель собака до что же ...</td>\n",
       "      <td>[-0.169  0.129  0.067  0.019  0.281 -0.245  0....</td>\n",
       "      <td>пять забавный морщинистый порода собака</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>контур три поперечный улица состоять до недавн...</td>\n",
       "      <td>[-0.158 -0.112 -0.325  0.05  -0.114  0.002 -0....</td>\n",
       "      <td>история улица ирининский в гомель</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>источник http infodays ru вообще он как то сам...</td>\n",
       "      <td>[ 0.084 -0.181  0.008  0.34  -0.03  -0.197 -0....</td>\n",
       "      <td>зачем дудь весь время спрашивать гость програм...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41 летний светлана зейналов решить окрестить 5...</td>\n",
       "      <td>[ 0.034 -0.119 -0.062  0.025  0.128 -0.041  0....</td>\n",
       "      <td>светлана зейналов крестить младший дочь</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>организовать преступный группировка гбао делат...</td>\n",
       "      <td>[-0.061 -0.015 -0.198 -0.047  0.054  0.029 -0....</td>\n",
       "      <td>гкнб бандит в гбао делать вид что расстаться с...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  content  \\\n",
       "itemId                                                      \n",
       "0       согласиться дорогой любитель собака до что же ...   \n",
       "1       контур три поперечный улица состоять до недавн...   \n",
       "2       источник http infodays ru вообще он как то сам...   \n",
       "3       41 летний светлана зейналов решить окрестить 5...   \n",
       "4       организовать преступный группировка гбао делат...   \n",
       "\n",
       "                                                    image  \\\n",
       "itemId                                                      \n",
       "0       [-0.169  0.129  0.067  0.019  0.281 -0.245  0....   \n",
       "1       [-0.158 -0.112 -0.325  0.05  -0.114  0.002 -0....   \n",
       "2       [ 0.084 -0.181  0.008  0.34  -0.03  -0.197 -0....   \n",
       "3       [ 0.034 -0.119 -0.062  0.025  0.128 -0.041  0....   \n",
       "4       [-0.061 -0.015 -0.198 -0.047  0.054  0.029 -0....   \n",
       "\n",
       "                                                    title  \n",
       "itemId                                                     \n",
       "0                 пять забавный морщинистый порода собака  \n",
       "1                       история улица ирининский в гомель  \n",
       "2       зачем дудь весь время спрашивать гость програм...  \n",
       "3                 светлана зейналов крестить младший дочь  \n",
       "4       гкнб бандит в гбао делать вид что расстаться с...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with open('items.json') as items_json:\n",
    "#     with Pool(cpu_count()) as pool:\n",
    "#         items_json_list = list(pool.imap(normalize_line, items_json))\n",
    "        \n",
    "# items = pd.DataFrame(items_json_list)\n",
    "# items.set_index('itemId')\n",
    "items.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/valeriy/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "#--------#\n",
    "\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "items['title'] = items['title'].str.split()\n",
    "# items['content'] = items['content'].str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = list(items['title'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymystem3 import Mystem\n",
    "\n",
    "conversion_table = {\n",
    "    'A': 'ADJ',\n",
    "    'ADV': 'ADV',\n",
    "    'ADVPRO': 'ADV',\n",
    "    'ANUM': 'ADJ',\n",
    "    'APRO': 'DET',\n",
    "    'COM': 'ADJ',\n",
    "    'CONJ': 'SCONJ',\n",
    "    'INTJ': 'INTJ',\n",
    "    'NONLEX': 'X',\n",
    "    'NUM': 'NUM',\n",
    "    'PART': 'PART',\n",
    "    'PR': 'ADP',\n",
    "    'S': 'NOUN',\n",
    "    'SPRO': 'PRON',\n",
    "    'UNKN': 'X',\n",
    "    'V': 'VERB'\n",
    "}\n",
    "\n",
    "m = Mystem()\n",
    "\n",
    "def tag(word='пожар'):\n",
    "    processed = m.analyze(word)[0]\n",
    "    if 'analysis' not in processed or not processed[\"analysis\"]:\n",
    "        return None\n",
    "    lemma = processed[\"analysis\"][0][\"lex\"].lower().strip()\n",
    "    pos = processed[\"analysis\"][0][\"gr\"].split(',')[0]\n",
    "    pos = pos.split('=')[0].strip()\n",
    "    pos = conversion_table.get(pos)\n",
    "    tagged = lemma + '_' + pos\n",
    "    return tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "russian_stopwords = set(stopwords.words(\"russian\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70397532753f45cfae1b5948319b81d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=328050.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sif = defaultdict(int)\n",
    "total_words = 0\n",
    "\n",
    "for title in tqdm_notebook(titles):\n",
    "    if isinstance(title, float):\n",
    "        continue\n",
    "    for word in title:\n",
    "        tagged = tag(word)\n",
    "        total_words += 1\n",
    "        if tagged not in w2v_model or word in russian_stopwords:\n",
    "            continue\n",
    "        else:\n",
    "            tagged_id = w2v_model.wv.vocab[tagged].index\n",
    "            sif[tagged_id] += 1\n",
    "sif = {word_id: num_occur / total_words for word_id, num_occur in sif.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35334"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sif_embeddings(sentences, model, alpha=1e-3):\n",
    "    \"\"\" Precomputes the indices of the sentences and uses the numpy indexing \n",
    "        to directly multiply and sum the vectors\n",
    "    \"\"\"\n",
    "    vlookup = model.wv.vocab\n",
    "    vectors = model.wv\n",
    "    output = []\n",
    "    for s in tqdm_notebook(sentences):\n",
    "        if isinstance(s, float):\n",
    "            output.append(np.zeros((300,)))\n",
    "            continue\n",
    "        # Pre-compute sentence indices\n",
    "        idx = [w2v_model.wv.vocab[tag(w)].index for w in s if tag(w) in w2v_model.wv.vocab]\n",
    "        # Note: vectors.sif is a pre-computed numpy array containing the weights for all the word-vectors.\n",
    "        weights = np.array([sif.get(word_id, 0) for word_id in idx])\n",
    "        v = weights @ w2v_model.wv.vectors[idx]\n",
    "        words_num = len(idx)\n",
    "        words_num -= np.sum(weights == 0)\n",
    "        if words_num:\n",
    "            v /= words_num\n",
    "        else:\n",
    "            v *= 0\n",
    "        output.append(v)\n",
    "    return np.vstack(output).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \"\"\"\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e6d6f632c3c4fc5888b83515ca11030",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=328050.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  del sys.path[0]\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_embs = sif_embeddings(titles, w2v_model)\n",
    "\n",
    "items_num = items.shape[0]\n",
    "del titles, items, sif, w2v_model\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(328050, 300)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_embs = np.load('title_embeddings.np.npy')\n",
    "title_embs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_embs_w2v = np.concatenate((title_embs, np.zeros((1, 300))))\n",
    "np.save('title_embeddings_w2v', title_embs_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_features = scipy.sparse.hstack((scipy.sparse.eye(items_num), \n",
    "                                     scipy.sparse.csr_matrix(title_embs)),\n",
    "                                    format='csr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d33f3533f874a92858d9657b290d326",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=42977.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "132"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "row = []\n",
    "col = []\n",
    "\n",
    "train_lines = sum(1 for line in open('train.json','r'))\n",
    "\n",
    "with open('train.json') as train_file:\n",
    "    for i, line in enumerate(tqdm_notebook(train_file, total=train_lines)):\n",
    "        json_line = json.loads(line)\n",
    "        for item, rating in json_line['trainRatings'].items():\n",
    "            data.append(2 * int(rating) - 1)\n",
    "            row.append(i)\n",
    "            col.append(int(item))\n",
    "train_int = scipy.sparse.coo_matrix((data, (row, col)))\n",
    "del data, row, col\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.sparse.save_npz('item_features_embedding.npz', item_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_features = scipy.sparse.load_npz(\"item_features_embedding.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(328050, 328350)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n"
     ]
    }
   ],
   "source": [
    "model = lightfm.LightFM(no_components=64, loss='logistic', learning_schedule='adadelta', random_state=42)\n",
    "model.fit(train_int, epochs=7, num_threads=cpu_count(), item_features=item_features, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.read_csv('random_benchmark.csv')\n",
    "sample['pred'] = model.predict(\n",
    "    sample.userId.values,\n",
    "    sample.itemId.values,\n",
    "    item_features=item_features,\n",
    "    num_threads=cpu_count(),\n",
    ")\n",
    "sample.sort_values(['userId', 'pred'], ascending=[True, False], inplace=True)\n",
    "sample.drop(columns=['pred'], inplace=True)\n",
    "sample.to_csv('lightfm_title_embedding_log.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions submit -c 2018-hse-ml-competition-04 -f lightfm_title_embedding_log.csv -m \"Title embedding log loss 5 epochs no_components=64\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
